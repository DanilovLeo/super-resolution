# -*- coding: utf-8 -*-
"""esr_bsr_gan_no_text_fin

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CxC_FQDjRyiNNefqiIAO9AhN-tX9eJpE

# Image Enhancement with BSRGAN and ESRGAN

This notebook uses BSRGAN (Blind Super-Resolution GAN) and ESRGAN to enhance images from Google Drive. These models work reliably in Google Colab without requiring Vulkan or complex dependencies.

## Install Required Libraries
"""

# Install required packages
!pip install opencv-python matplotlib numpy torch torchvision pytesseract
!pip install skimage scikit-image

import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from google.colab import drive
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from scipy.ndimage import gaussian_filter

"""## Mount Google Drive and Setup"""

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Set up directories
# CHANGE THIS PATH to your input directory in Google Drive
drive_input_dir = '/content/drive/MyDrive/images_no_text'

# Output directory in Google Drive for enhanced images
drive_output_dir = '/content/drive/MyDrive/gan_output_images'

# Directory for intermediate (degraded) images
drive_degraded_dir = '/content/drive/MyDrive/gan_degraded_images'

# Local directories for processing
local_input_dir = '/content/input_images'
local_output_dir = '/content/output_images'
local_degraded_dir = '/content/degraded_images'

# Create all directories
os.makedirs(drive_output_dir, exist_ok=True)
os.makedirs(drive_degraded_dir, exist_ok=True)
os.makedirs(local_input_dir, exist_ok=True)
os.makedirs(local_output_dir, exist_ok=True)
os.makedirs(local_degraded_dir, exist_ok=True)

"""## Download BSRGAN and ESRGAN Models"""

# Create models directory
!mkdir -p /content/models

# Download pre-trained BSRGAN model
!wget -nc https://github.com/cszn/KAIR/releases/download/v1.0/BSRGAN.pth -P /content/models/

!gdown --id 1TPrz5QKd8DHHt1k8SRtm6tMiPjz_Qene -O /content/models/RRDB_ESRGAN_x4.pth

"""## Define RRDB Model Architecture"""

# Define the model architecture
class ResidualDenseBlock(nn.Module):
    def __init__(self, nf=64, gc=32, bias=True):
        super(ResidualDenseBlock, self).__init__()
        # gc: growth channel, i.e. intermediate channels
        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)
        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)
        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)
        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)
        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)
        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)

    def forward(self, x):
        x1 = self.lrelu(self.conv1(x))
        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))
        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))
        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))
        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
        return x5 * 0.2 + x


class RRDB(nn.Module):
    '''Residual in Residual Dense Block'''
    def __init__(self, nf, gc=32):
        super(RRDB, self).__init__()
        self.RDB1 = ResidualDenseBlock(nf, gc)
        self.RDB2 = ResidualDenseBlock(nf, gc)
        self.RDB3 = ResidualDenseBlock(nf, gc)

    def forward(self, x):
        out = self.RDB1(x)
        out = self.RDB2(out)
        out = self.RDB3(out)
        return out * 0.2 + x


class RRDBNet(nn.Module):
    def __init__(self, in_nc=3, out_nc=3, nf=64, nb=23, gc=32, scale=4, upscale=False):
        super(RRDBNet, self).__init__()
        self.scale = scale
        RRDB_block_f = lambda nf: RRDB(nf, gc=gc)

        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)
        self.RRDB_trunk = self.make_layer(RRDB_block_f, nf, nb)
        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)

        # Upsampling layers
        self.upscale = upscale
        if self.upscale:
            self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
            self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
            self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
            self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)
            self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)

    def make_layer(self, block, nf, n_layers):
        layers = []
        for _ in range(n_layers):
            layers.append(block(nf))
        return nn.Sequential(*layers)

    def forward(self, x):
        fea = self.conv_first(x)
        trunk = self.RRDB_trunk(fea)
        trunk = self.trunk_conv(trunk)
        fea = fea + trunk

        if self.upscale:
            # Upsampling
            fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))
            fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))
            out = self.conv_last(self.lrelu(self.HRconv(fea)))
        else:
            # No upsampling, just apply a final convolution
            out = fea

        return out

"""## Copy Images from Google Drive"""

def copy_images_from_drive(drive_input_dir, local_input_dir):
    """Copy images from Google Drive to local directory"""
    # Check if the input directory exists
    if not os.path.exists(drive_input_dir):
        print(f"Error: The directory {drive_input_dir} does not exist in your Google Drive.")
        return []

    # Get list of image files
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
    image_files = [f for f in os.listdir(drive_input_dir)
                  if os.path.isfile(os.path.join(drive_input_dir, f)) and
                  f.lower().endswith(image_extensions)]

    if not image_files:
        print(f"No image files found in {drive_input_dir}")
        return []

    print(f"Found {len(image_files)} images in {drive_input_dir}")
    print("Copying images to local directory...")

    # Copy each image to local directory
    for filename in image_files:
        src_path = os.path.join(drive_input_dir, filename)
        dst_path = os.path.join(local_input_dir, filename)
        os.system(f'cp "{src_path}" "{dst_path}"')
        print(f"Copied {filename}")

    print(f"Successfully copied {len(image_files)} images to {local_input_dir}")
    return image_files

"""## Create degraded images"""

def create_degraded_images(image_files, local_input_dir, local_degraded_dir, drive_degraded_dir, scale_factor=0.5):
    """Create degraded (low-resolution) versions of input images"""
    degraded_files = []

    for filename in image_files:
        input_path = os.path.join(local_input_dir, filename)
        degraded_filename = os.path.splitext(filename)[0] + '_degraded' + os.path.splitext(filename)[1]
        degraded_path = os.path.join(local_degraded_dir, degraded_filename)

        # Read image
        img = cv2.imread(input_path, cv2.IMREAD_COLOR)
        if img is None:
            print(f"Error: Could not read image {input_path}")
            continue

        # Get original dimensions
        h, w = img.shape[:2]
        print(f"Original image dimensions: {w}x{h}")

        # 1. Downscale to much lower resolution
        lr_h, lr_w = int(h * scale_factor), int(w * scale_factor)
        img_lr = cv2.resize(img, (lr_w, lr_h), interpolation=cv2.INTER_CUBIC)
        print(f"Downscaled to: {lr_w}x{lr_h}")

        # 2. Apply JPEG compression artifacts
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50]  # Low quality JPEG
        _, buffer = cv2.imencode('.jpg', img_lr, encode_param)
        img_lr = cv2.imdecode(buffer, cv2.IMREAD_COLOR)

        # 3. Apply slight blur to simulate lack of sharp focus
        img_lr = cv2.GaussianBlur(img_lr, (3, 3), 0.8)

        # Save this truly degraded image
        cv2.imwrite(degraded_path, img_lr)
        print(f"Saved degraded image with dimensions: {img_lr.shape[1]}x{img_lr.shape[0]}")

        # Copy to Google Drive
        drive_degraded_path = os.path.join(drive_degraded_dir, degraded_filename)
        os.system(f'cp "{degraded_path}" "{drive_degraded_path}"')

        degraded_files.append(degraded_filename)
        print(f"Created degraded image: {degraded_filename}")

    return degraded_files

"""## Metrics Functions"""

def calculate_metrics(original_img, enhanced_img):
    """Calculate image quality metrics"""
    # Resize enhanced image to match original if needed
    if original_img.shape != enhanced_img.shape:
        enhanced_img = cv2.resize(enhanced_img, (original_img.shape[1], original_img.shape[0]),
                                 interpolation=cv2.INTER_CUBIC)

    # Convert to Y channel (luminance) for more accurate metrics
    def rgb_to_y(img):
        return 0.299 * img[:,:,0] + 0.587 * img[:,:,1] + 0.114 * img[:,:,2]

    original_y = rgb_to_y(original_img)
    enhanced_y = rgb_to_y(enhanced_img)

    # Calculate PSNR
    psnr = peak_signal_noise_ratio(original_y, enhanced_y, data_range=255)

    # Calculate SSIM
    ssim = structural_similarity(original_y, enhanced_y, data_range=255)

    # Calculate sharpness (variance of Laplacian)
    def calculate_sharpness(img):
        gray = img if len(img.shape) == 2 else rgb_to_y(img)
        return cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F).var()

    original_sharpness = calculate_sharpness(original_img)
    enhanced_sharpness = calculate_sharpness(enhanced_img)
    sharpness_increase = (enhanced_sharpness - original_sharpness) / (original_sharpness + 1e-8) * 100

    # Calculate detail retention (high-frequency content)
    def calculate_details(img):
        gray = img if len(img.shape) == 2 else rgb_to_y(img)
        # Apply Gaussian blur
        blurred = gaussian_filter(gray, sigma=3)
        # Calculate high-frequency content
        high_freq = np.abs(gray - blurred)
        return np.mean(high_freq)

    original_details = calculate_details(original_img)
    enhanced_details = calculate_details(enhanced_img)
    detail_increase = (enhanced_details - original_details) / (original_details + 1e-8) * 100

    metrics = {
        'psnr': psnr,
        'ssim': ssim,
        'original_sharpness': original_sharpness,
        'enhanced_sharpness': enhanced_sharpness,
        'sharpness_increase': sharpness_increase,
        'original_details': original_details,
        'enhanced_details': enhanced_details,
        'detail_increase': detail_increase
    }

    return metrics

"""## Initialize Models"""

def load_model(model_path, model_type='bsrgan'):
    """Load the BSRGAN or ESRGAN model"""
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # Create model
    if model_type == 'bsrgan':
        model = RRDBNet(in_nc=3, out_nc=3, nf=64, nb=23, gc=32, scale=4, upscale=True)
        print("Loading BSRGAN model...")
    else:  # esrgan
        model = RRDBNet(in_nc=3, out_nc=3, nf=64, nb=23, gc=32, scale=4, upscale=True)
        print("Loading ESRGAN model...")

    # Load state dictionary
    state_dict = torch.load(model_path, map_location=device)

    # Handle different state dict formats
    if 'params_ema' in state_dict:
        model.load_state_dict(state_dict['params_ema'], strict=True)
    elif 'params' in state_dict:
        model.load_state_dict(state_dict['params'], strict=True)
    else:
        model.load_state_dict(state_dict, strict=True)

    model.eval()
    model = model.to(device)

    return model, device

"""## Process Images"""

def process_image(degraded_path, output_path, model, device, original_path=None, tile_size=None):
    """Process a single image with the model with improved post-processing"""
    # Read image
    img = cv2.imread(degraded_path, cv2.IMREAD_COLOR)
    if img is None:
        print(f"Error: Could not read image {degraded_path}")
        return None, None, None

    # Print original size to debug
    print(f"Processing degraded image with dimensions: {img.shape[1]}x{img.shape[0]}")

    # Prepare input
    img = img.astype(np.float32) / 255.
    img = torch.from_numpy(np.transpose(img, (2, 0, 1))).unsqueeze(0).to(device)

    # Get original image dimensions
    _, _, h_old, w_old = img.size()

    # Process image
    with torch.no_grad():
        # Use tiled processing for large images to avoid out-of-memory
        if tile_size is not None and (h_old > tile_size or w_old > tile_size):
            # Process large image in tiles
            print(f"Processing large image in tiles of size {tile_size}")
            scale = 4  # upscale factor
            tile = tile_size
            tile_overlap = 32  # overlap between tiles
            stride = tile - tile_overlap

            # Initialize output tensor
            output = torch.zeros(1, 3, h_old*scale, w_old*scale, device=device)
            weight = torch.zeros_like(output)

            # Process each tile
            for h_idx in range(0, h_old, stride):
                for w_idx in range(0, w_old, stride):
                    # Handle boundary cases
                    h_end = min(h_idx + tile, h_old)
                    w_end = min(w_idx + tile, w_old)
                    h_start = max(0, h_end - tile)
                    w_start = max(0, w_end - tile)

                    # Extract tile
                    in_patch = img[:, :, h_start:h_end, w_start:w_end]

                    # Process tile
                    out_patch = model(in_patch)

                    # Get output coordinates
                    out_h_start = h_start * scale
                    out_w_start = w_start * scale
                    out_h_end = h_end * scale
                    out_w_end = w_end * scale

                    # Apply weight mask for smooth blending
                    weight_patch = torch.ones_like(out_patch)
                    output[:, :, out_h_start:out_h_end, out_w_start:out_w_end] += out_patch
                    weight[:, :, out_h_start:out_h_end, out_w_start:out_w_end] += weight_patch

            # Average overlapping regions
            output = output / weight
        else:
            # Process entire image at once
            output = model(img)

    # Save output image with enhanced post-processing
    output = output.data.squeeze().float().cpu().clamp_(0, 1).numpy()
    output = np.transpose(output, (1, 2, 0))

    # Apply additional sharpening to make enhancement more visible
    output_uint8 = (output * 255.0).round().astype(np.uint8)

    # Apply contrast enhancement
    lab = cv2.cvtColor(output_uint8, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    enhanced_lab = cv2.merge((l, a, b))
    enhanced_rgb = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)

    # Apply slight sharpening
    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    enhanced_rgb = cv2.filter2D(enhanced_rgb, -1, kernel)

    # Preserve colors from original image if provided
    if original_path is not None:
        try:
            # Load original image
            original = cv2.imread(original_path)
            if original is not None:
                # Resize original to match enhanced image size
                original_resized = cv2.resize(original, (enhanced_rgb.shape[1], enhanced_rgb.shape[0]),
                                            interpolation=cv2.INTER_LINEAR)

                # Convert to RGB
                original_rgb = cv2.cvtColor(original_resized, cv2.COLOR_BGR2RGB)

                # Convert to HSV to separate color and brightness
                original_hsv = cv2.cvtColor(original_rgb, cv2.COLOR_RGB2HSV)
                enhanced_hsv = cv2.cvtColor(enhanced_rgb, cv2.COLOR_RGB2HSV)

                # Take H and S from original, V from enhanced
                h, s, _ = cv2.split(original_hsv)
                _, _, v = cv2.split(enhanced_hsv)

                # Create new HSV image
                merged_hsv = cv2.merge([h, s, v])

                # Convert back to RGB
                merged_rgb = cv2.cvtColor(merged_hsv, cv2.COLOR_HSV2RGB)

                # Use merged colors
                enhanced_rgb = merged_rgb
                print("Color preservation applied")
            else:
                print("Could not read original image for color preservation")
        except Exception as e:
            print(f"Error applying color preservation: {e}")
            # Continue without color preservation

    # Save the enhanced output
    cv2.imwrite(output_path, cv2.cvtColor(enhanced_rgb, cv2.COLOR_RGB2BGR))
    print(f"Saved enhanced image with dimensions: {enhanced_rgb.shape[1]}x{enhanced_rgb.shape[0]}")

    # Prepare images for display
    input_img = cv2.imread(degraded_path, cv2.IMREAD_COLOR)
    input_img_rgb = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)
    output_img_rgb = enhanced_rgb

    # Calculate metrics
    metrics = calculate_metrics(input_img_rgb, output_img_rgb)

    # Print metrics
    print("\nImage Quality Metrics:")
    print(f"PSNR: {metrics['psnr']:.2f} dB")
    print(f"SSIM: {metrics['ssim']:.4f}")
    print(f"Sharpness increase: {metrics['sharpness_increase']:.2f}%")
    print(f"Detail increase: {metrics['detail_increase']:.2f}%")

    return input_img_rgb, output_img_rgb, metrics

def process_all_images(image_files, model, device, local_input_dir, local_degraded_dir, local_output_dir, drive_output_dir, model_name="BSRGAN", tile_size=None):
    """Process all images with the model - displays a clear before/degraded/after comparison"""
    all_metrics = []

    for filename in image_files:
        base_filename = os.path.splitext(filename)[0]
        degraded_filename = base_filename + '_degraded' + os.path.splitext(filename)[1]

        input_path = os.path.join(local_input_dir, filename)
        degraded_path = os.path.join(local_degraded_dir, degraded_filename)
        output_filename = base_filename + f'_{model_name}.png'
        output_path = os.path.join(local_output_dir, output_filename)

        print(f"\n{'='*80}\nProcessing {filename} with {model_name}...")
        print(f"Input path: {input_path}")
        print(f"Degraded path: {degraded_path}")
        print(f"Output path: {output_path}")

        try:
            # Process image - capture the metrics - pass original_path
            degraded_img_rgb, output_img_rgb, metrics = process_image(
                degraded_path, output_path, model, device, original_path=input_path, tile_size=tile_size
            )

            if degraded_img_rgb is None or output_img_rgb is None:
                print(f"Error processing {filename}")
                continue

            # Store metrics for later analysis
            metrics['filename'] = filename
            metrics['model'] = model_name
            all_metrics.append(metrics)

            # Copy to Google Drive
            drive_output_path = os.path.join(drive_output_dir, output_filename)
            os.system(f'cp "{output_path}" "{drive_output_path}"')
            print(f"Saved to Google Drive: {drive_output_path}")

            # Read original image for display
            orig_img = cv2.imread(input_path, cv2.IMREAD_COLOR)
            orig_img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)

            # Display before/intermediate/after comparison
            plt.figure(figsize=(20, 12))

            # Original image
            plt.subplot(1, 3, 1)
            plt.imshow(orig_img_rgb)
            plt.title(f"Original: {filename}\nDimensions: {orig_img.shape[1]}x{orig_img.shape[0]}", fontsize=12)
            plt.axis('off')

            # Degraded image - adjusted to original size for better comparison
            plt.subplot(1, 3, 2)
            degraded_resized = cv2.resize(degraded_img_rgb, (orig_img.shape[1], orig_img.shape[0]),
                                     interpolation=cv2.INTER_NEAREST)
            plt.imshow(degraded_resized)
            plt.title(f"Degraded: {degraded_filename}\nDimensions: {degraded_img_rgb.shape[1]}x{degraded_img_rgb.shape[0]}\n(Resized for display)", fontsize=12)
            plt.axis('off')

            # Enhanced image
            plt.subplot(1, 3, 3)
            enhanced_resized = cv2.resize(output_img_rgb, (orig_img.shape[1], orig_img.shape[0]),
                                     interpolation=cv2.INTER_CUBIC) if output_img_rgb.shape != orig_img.shape else output_img_rgb
            plt.imshow(enhanced_resized)
            plt.title(f"Enhanced ({model_name}): {output_filename}\nDimensions: {output_img_rgb.shape[1]}x{output_img_rgb.shape[0]}\nPSNR: {metrics['psnr']:.2f} dB, SSIM: {metrics['ssim']:.4f}\nSharpness Increase: {metrics['sharpness_increase']:.2f}%", fontsize=12)
            plt.axis('off')

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"Error processing {filename}: {e}")
            import traceback
            traceback.print_exc()

    print(f"Processing with {model_name} complete!")
    return all_metrics

"""## Compare results of models"""

def compare_model_results(all_results, model1="BSRGAN", model2="ESRGAN"):
    """Compare results from two models"""
    # Group results by model
    model1_results = [r for r in all_results if r['model'] == model1]
    model2_results = [r for r in all_results if r['model'] == model2]

    if not model1_results or not model2_results:
        print(f"Not enough data to compare {model1} and {model2}")
        return

    # Calculate averages
    metrics_to_average = ['psnr', 'ssim', 'sharpness_increase', 'detail_increase']
    model1_avg = {m: sum(r[m] for r in model1_results) / len(model1_results) for m in metrics_to_average}
    model2_avg = {m: sum(r[m] for r in model2_results) / len(model2_results) for m in metrics_to_average}

    # Print average results
    print(f"\nAverage Metrics Comparison ({model1} vs {model2}):")
    print(f"{'Metric':<20} {model1:<15} {model2:<15}")
    print("-" * 50)
    for metric in metrics_to_average:
        print(f"{metric:<20} {model1_avg[metric]:<15.2f} {model2_avg[metric]:<15.2f}")

    # Create visualization
    metrics_to_plot = ['psnr', 'ssim', 'sharpness_increase']
    labels = ['PSNR (dB)', 'SSIM (x100)', 'Sharpness Increase (%)']

    model1_values = [model1_avg['psnr'], model1_avg['ssim']*100, model1_avg['sharpness_increase']]
    model2_values = [model2_avg['psnr'], model2_avg['ssim']*100, model2_avg['sharpness_increase']]

    x = np.arange(len(metrics_to_plot))
    width = 0.35

    plt.figure(figsize=(12, 6))
    plt.bar(x - width/2, model1_values, width, label=model1)
    plt.bar(x + width/2, model2_values, width, label=model2)

    plt.xlabel('Metrics')
    plt.ylabel('Values')
    plt.title(f'Average Image Quality Metrics Comparison ({model1} vs {model2})')
    plt.xticks(x, labels)
    plt.legend()

    plt.tight_layout()
    plt.show()

"""## Main Part"""

def main():
    # Copy images from Google Drive
    image_files = copy_images_from_drive(drive_input_dir, local_input_dir)

    if not image_files:
        print("No images found to process.")
        return

    # Create degraded versions
    print("\n=== Creating degraded versions of images ===")
    create_degraded_images(image_files, local_input_dir, local_degraded_dir, drive_degraded_dir, scale_factor=0.5)

    # Load models
    print("\n=== Loading GAN models ===")
    bsrgan_model, device = load_model('/content/models/BSRGAN.pth', model_type='bsrgan')
    esrgan_model, _ = load_model('/content/models/RRDB_ESRGAN_x4.pth', model_type='esrgan')

    # Process images with both models - use smaller tile size for better memory usage
    print("\n=== Processing with BSRGAN ===")
    bsrgan_results = process_all_images(
        image_files, bsrgan_model, device,
        local_input_dir, local_degraded_dir, local_output_dir, drive_output_dir,
        model_name="BSRGAN", tile_size=256
    )

    print("\n=== Processing with ESRGAN ===")
    esrgan_results = process_all_images(
        image_files, esrgan_model, device,
        local_input_dir, local_degraded_dir, local_output_dir, drive_output_dir,
        model_name="ESRGAN", tile_size=256
    )

    # Compare results
    print("\n=== Comparing Model Results ===")
    all_results = bsrgan_results + esrgan_results
    compare_model_results(all_results, "BSRGAN", "ESRGAN")

if __name__ == "__main__":
    main()

