# -*- coding: utf-8 -*-
"""sd_sr_no_text

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LVI-pk9hJ_jXfCgeSDv5IcYAy5OXtS5S

# Implementation of SD for super-resolution on landscape images (without text)
"""

# Install required packages
!pip install opencv-python matplotlib numpy torch torchvision diffusers transformers accelerate xformers
!pip install git+https://github.com/openai/CLIP.git

"""## Import Libraries"""

import os
import cv2
import numpy as np
import torch
from diffusers import StableDiffusionImg2ImgPipeline, UniPCMultistepScheduler
import matplotlib.pyplot as plt
from google.colab import drive
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from scipy.ndimage import gaussian_filter
import clip
from PIL import Image
from huggingface_hub import login

"""## Mount Google Drive and Setup"""

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Authenticate with Hugging Face
from google.colab import userdata

try:
    hf_token = userdata.get('HF_TOKEN')
    if hf_token:
        os.environ['HUGGINGFACE_TOKEN'] = hf_token
        login(token=hf_token)
        print("✓ Successfully authenticated with Hugging Face!")
    else:
        print("⚠️ HF_TOKEN not found in secrets")
except Exception as e:
    print(f"❌ Authentication error: {e}")

# Set up directories
drive_input_dir = '/content/drive/MyDrive/images_no_text'
drive_output_dir = '/content/drive/MyDrive/stablesr_final_output_no_text'
drive_degraded_dir = '/content/drive/MyDrive/gan_degraded_images'

local_input_dir = '/content/input_images'
local_output_dir = '/content/output_images'
local_degraded_dir = '/content/degraded_images'

# Create directories
for dir_path in [drive_output_dir, drive_degraded_dir, local_input_dir, local_output_dir, local_degraded_dir]:
    os.makedirs(dir_path, exist_ok=True)

"""## Copy Images from Google Drive"""

def copy_images_from_drive(drive_input_dir, local_input_dir):
    """Copy images from Google Drive to local directory"""
    if not os.path.exists(drive_input_dir):
        print(f"Error: Directory {drive_input_dir} does not exist.")
        return []

    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
    image_files = [f for f in os.listdir(drive_input_dir)
                  if os.path.isfile(os.path.join(drive_input_dir, f)) and
                  f.lower().endswith(image_extensions)]

    if not image_files:
        print(f"No image files found in {drive_input_dir}")
        return []

    print(f"Found {len(image_files)} images. Copying...")
    for filename in image_files:
        src_path = os.path.join(drive_input_dir, filename)
        dst_path = os.path.join(local_input_dir, filename)
        os.system(f'cp "{src_path}" "{dst_path}"')
    return image_files

"""## Create Degraded images"""

def create_degraded_images(image_files, local_input_dir, local_degraded_dir, drive_degraded_dir, scale_factor=0.5):
    """Create degraded versions of images"""
    degraded_files = []
    for filename in image_files:
        input_path = os.path.join(local_input_dir, filename)
        degraded_filename = os.path.splitext(filename)[0] + '_degraded' + os.path.splitext(filename)[1]
        degraded_path = os.path.join(local_degraded_dir, degraded_filename)

        img = cv2.imread(input_path, cv2.IMREAD_COLOR)
        if img is None:
            continue

        h, w = img.shape[:2]
        lr_h, lr_w = int(h * scale_factor), int(w * scale_factor)

        # Downscale and degrade
        img_lr = cv2.resize(img, (lr_w, lr_h), interpolation=cv2.INTER_CUBIC)
        _, buffer = cv2.imencode('.jpg', img_lr, [cv2.IMWRITE_JPEG_QUALITY, 50])
        img_lr = cv2.imdecode(buffer, cv2.IMREAD_COLOR)
        img_lr = cv2.GaussianBlur(img_lr, (3, 3), 0.8)

        cv2.imwrite(degraded_path, img_lr)
        os.system(f'cp "{degraded_path}" "{os.path.join(drive_degraded_dir, degraded_filename)}"')
        degraded_files.append(degraded_filename)
    return degraded_files

"""## Initialize CLIP Model for Evaluation"""

def load_clip_model():
    """Load CLIP model"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

"""## Metrics Functions"""

def calculate_metrics(original_img, enhanced_img, clip_model=None, clip_preprocess=None, prompt=None, device=None):
    """Calculate image quality metrics"""
    if original_img.shape != enhanced_img.shape:
        enhanced_img = cv2.resize(enhanced_img, (original_img.shape[1], original_img.shape[0]),
                                 interpolation=cv2.INTER_CUBIC)

    def rgb_to_y(img):
        return 0.299 * img[:,:,0] + 0.587 * img[:,:,1] + 0.114 * img[:,:,2]

    original_y = rgb_to_y(original_img)
    enhanced_y = rgb_to_y(enhanced_img)

    psnr = peak_signal_noise_ratio(original_y, enhanced_y, data_range=255)
    ssim = structural_similarity(original_y, enhanced_y, data_range=255)

    def calculate_sharpness(img):
        gray = img if len(img.shape) == 2 else rgb_to_y(img)
        return cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F).var()

    original_sharpness = calculate_sharpness(original_img)
    enhanced_sharpness = calculate_sharpness(enhanced_img)
    sharpness_increase = (enhanced_sharpness - original_sharpness) / (original_sharpness + 1e-8) * 100

    def calculate_details(img):
        gray = img if len(img.shape) == 2 else rgb_to_y(img)
        blurred = gaussian_filter(gray, sigma=3)
        high_freq = np.abs(gray - blurred)
        return np.mean(high_freq)

    original_details = calculate_details(original_img)
    enhanced_details = calculate_details(enhanced_img)
    detail_increase = (enhanced_details - original_details) / (original_details + 1e-8) * 100

    metrics = {
        'psnr': psnr,
        'ssim': ssim,
        'sharpness_increase': sharpness_increase,
        'detail_increase': detail_increase
    }

    # Add CLIP metrics if available
    if clip_model is not None and clip_preprocess is not None and device is not None:
        try:
            original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
            enhanced_rgb = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)

            original_pil = Image.fromarray(original_rgb)
            enhanced_pil = Image.fromarray(enhanced_rgb)

            with torch.no_grad():
                original_features = clip_model.encode_image(clip_preprocess(original_pil).unsqueeze(0).to(device))
                enhanced_features = clip_model.encode_image(clip_preprocess(enhanced_pil).unsqueeze(0).to(device))

                original_features = original_features / original_features.norm(dim=-1, keepdim=True)
                enhanced_features = enhanced_features / enhanced_features.norm(dim=-1, keepdim=True)

                clip_img_similarity = torch.nn.functional.cosine_similarity(original_features, enhanced_features).item()
                metrics['clip_img_similarity'] = clip_img_similarity

                if prompt:
                    text = clip.tokenize([prompt]).to(device)
                    text_features = clip_model.encode_text(text)
                    text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                    prompt_img_similarity = torch.nn.functional.cosine_similarity(enhanced_features, text_features).item()
                    metrics['prompt_img_similarity'] = prompt_img_similarity
        except Exception as e:
            print(f"CLIP metric error: {e}")

    return metrics

"""## Define StableSR Model"""

def load_stablesr_model():
    """Load StableSR model"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    try:
        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            use_auth_token=True,
            safety_checker=None,
            requires_safety_checker=False
        )
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        pipe = pipe.to(device)
        pipe.enable_model_cpu_offload()
        if hasattr(pipe, 'enable_xformers_memory_efficient_attention'):
            pipe.enable_xformers_memory_efficient_attention()

        print("Successfully loaded StableSR model")
        return pipe, device
    except Exception as e:
        print(f"Error loading model: {e}")
        return None, device

def get_landscape_prompts():
    """Get specific prompts for each landscape image"""
    return [
        "A towering waterfall cascading down a rugged cliff at sunset, golden light illuminating mist and vibrant greenery below, ultra-detailed, photorealistic, high-quality super-resolution, realistic water spray, dramatic sky, fine rock textures",
        "A tranquil marshland with still, reflective water surrounded by tall reeds and distant tree line under soft daylight, super-resolution, ultra-detailed, photorealistic, crisp reed structures, subtle water ripples",
        "A fast mountain stream rushing through rocky canyon with turquoise water and autumn foliage, super-resolution, photorealistic, highly detailed rock surfaces and whitewater foam",
        "A high-angle view of terraced green hillsides overlooking a deep mountain valley bathed in morning sunbeams through clouds, super-resolution, ultra-detailed, realistic light rays, fine terrain textures",
        "A small waterfall flowing over mossy rocks in early spring, bare trees above and bright blue sky, super-resolution, photorealistic, crisp water flow, detailed rock and bark textures",
        "Aerial view of a long turquoise lake flanked by dense green forests and distant mountains under partly cloudy sky, super-resolution, ultra-detailed, realistic water gradients, fine foliage textures",
        "A remote alpine lake in a barren mountainous plateau with misty clouds and muted colors, super-resolution, photorealistic, highly detailed terrain and water reflections",
        "A misty autumn mountainside with low-lying clouds drifting among colorful trees reflected in a calm lake, super-resolution, ultra-detailed, realistic leaf textures and soft cloud wisps",
        "A crystal-clear mountain lake perfectly mirroring snow-capped peaks and fluffy white clouds against a bright blue sky, super-resolution, photorealistic, ultra-detailed water reflection, fine rock and tree details",
        "A lush green rolling landscape with a winding river under a vivid blue sky dotted with small white clouds, super-resolution, photorealistic, ultra-detailed grass and tree textures, realistic water highlights"
    ]

"""## Process Images"""

def process_image_stablesr(degraded_path, output_path, pipe, device, prompt,
                          clip_model=None, clip_preprocess=None, original_path=None,
                          num_inference_steps=20):
    """Process a single image with StableSR"""
    img = cv2.imread(degraded_path, cv2.IMREAD_COLOR)
    if img is None:
        print(f"Error reading {degraded_path}")
        return None, None, None

    print(f"Processing: {degraded_path}")

    # Convert to PIL and upscale
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_pil = Image.fromarray(img_rgb)
    scale_factor = 4
    target_size = (img_pil.width * scale_factor, img_pil.height * scale_factor)
    img_upscaled = img_pil.resize(target_size, Image.BICUBIC)

    try:
        # Process with conservative settings
        result = pipe(
            prompt=prompt,
            image=img_upscaled,
            strength=0.15,  # Very low strength
            guidance_scale=3.0,  # Low guidance
            num_inference_steps=num_inference_steps,
        ).images[0]

        # Convert back to OpenCV format
        enhanced_img = cv2.cvtColor(np.array(result), cv2.COLOR_RGB2BGR)

        # Save result
        cv2.imwrite(output_path, enhanced_img)
        print(f"Saved: {output_path}")

        # Calculate metrics
        metrics = calculate_metrics(
            img, enhanced_img,
            clip_model=clip_model,
            clip_preprocess=clip_preprocess,
            prompt=prompt,
            device=device
        )

        # Print metrics
        print(f"PSNR: {metrics['psnr']:.2f} dB")
        print(f"SSIM: {metrics['ssim']:.4f}")
        print(f"Sharpness increase: {metrics['sharpness_increase']:.2f}%")

        return img, enhanced_img, metrics

    except Exception as e:
        print(f"Processing error: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None

def process_all_images_stablesr(image_files, pipe, device, clip_model, clip_preprocess,
                               local_input_dir, local_degraded_dir, local_output_dir, drive_output_dir,
                               prompts=None):
    """Process all images with StableSR"""
    all_metrics = []

    # Make sure we have enough prompts
    if prompts and len(prompts) < len(image_files):
        prompts = (prompts * ((len(image_files) // len(prompts)) + 1))[:len(image_files)]

    for i, filename in enumerate(image_files):
        base_filename = os.path.splitext(filename)[0]
        degraded_filename = base_filename + '_degraded' + os.path.splitext(filename)[1]

        input_path = os.path.join(local_input_dir, filename)
        degraded_path = os.path.join(local_degraded_dir, degraded_filename)
        output_filename = base_filename + '_StableSR.png'
        output_path = os.path.join(local_output_dir, output_filename)

        # Get prompt for this image
        prompt = prompts[i] if prompts and i < len(prompts) else "high quality landscape, enhanced detail"

        print(f"\n{'='*80}\nProcessing {filename} with StableSR...")
        print(f"Prompt: {prompt}")

        try:
            degraded_img, output_img, metrics = process_image_stablesr(
                degraded_path, output_path, pipe, device, prompt,
                clip_model=clip_model, clip_preprocess=clip_preprocess, original_path=input_path
            )

            if degraded_img is None or output_img is None:
                print(f"Error processing {filename}")
                continue

            # Store metrics
            metrics['filename'] = filename
            metrics['model'] = "StableSR"
            all_metrics.append(metrics)

            # Copy to Google Drive
            drive_output_path = os.path.join(drive_output_dir, output_filename)
            os.system(f'cp "{output_path}" "{drive_output_path}"')
            print(f"Saved to Drive: {drive_output_path}")

            # Display comparison
            orig_img = cv2.imread(input_path, cv2.IMREAD_COLOR)
            orig_img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)
            degraded_img_rgb = cv2.cvtColor(degraded_img, cv2.COLOR_BGR2RGB)
            output_img_rgb = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)

            plt.figure(figsize=(20, 12))

            # Original
            plt.subplot(1, 3, 1)
            plt.imshow(orig_img_rgb)
            plt.title(f"Original: {filename}\nDimensions: {orig_img.shape[1]}x{orig_img.shape[0]}", fontsize=12)
            plt.axis('off')

            # Degraded
            plt.subplot(1, 3, 2)
            degraded_resized = cv2.resize(degraded_img_rgb, (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_NEAREST)
            plt.imshow(degraded_resized)
            plt.title(f"Degraded: {degraded_filename}\nDimensions: {degraded_img.shape[1]}x{degraded_img.shape[0]}\n(Resized for display)", fontsize=12)
            plt.axis('off')

            # Enhanced
            plt.subplot(1, 3, 3)
            enhanced_resized = cv2.resize(output_img_rgb, (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_CUBIC) if output_img.shape != orig_img.shape else output_img_rgb
            plt.imshow(enhanced_resized)

            title_text = f"Enhanced (StableSR): {output_filename}\nDimensions: {output_img.shape[1]}x{output_img.shape[0]}\n"
            title_text += f"PSNR: {metrics['psnr']:.2f} dB, SSIM: {metrics['ssim']:.4f}\n"
            title_text += f"Sharpness Increase: {metrics['sharpness_increase']:.2f}%"

            if 'clip_img_similarity' in metrics:
                title_text += f"\nCLIP Image Sim: {metrics['clip_img_similarity']:.4f}"
            if 'prompt_img_similarity' in metrics:
                title_text += f", Prompt Sim: {metrics['prompt_img_similarity']:.4f}"

            plt.title(title_text, fontsize=12)
            plt.axis('off')

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"Error processing {filename}: {e}")
            import traceback
            traceback.print_exc()

    print(f"\nProcessing complete! Processed {len(all_metrics)} images")
    return all_metrics

"""## Compare Results Function"""

def compare_model_results(all_results, model1="StableSR"):
    """Analyze results from StableSR"""
    if not all_results:
        print("No results to analyze")
        return

    metrics_to_average = ['psnr', 'ssim', 'sharpness_increase', 'detail_increase', 'clip_img_similarity', 'prompt_img_similarity']
    avg_metrics = {}

    for metric in metrics_to_average:
        valid_results = [r[metric] for r in all_results if metric in r]
        if valid_results:
            avg_metrics[metric] = sum(valid_results) / len(valid_results)

    print(f"\nAverage Metrics for {model1}:")
    print(f"{'Metric':<20} {'Value':<15}")
    print("-" * 35)
    for metric, value in avg_metrics.items():
        print(f"{metric:<20} {value:<15.4f}")

    # Create visualization
    metrics_to_plot = ['psnr', 'ssim', 'clip_img_similarity']
    labels = ['PSNR (dB)', 'SSIM', 'CLIP Image Similarity']

    values = []
    for metric in metrics_to_plot:
        if metric in avg_metrics:
            if metric == 'ssim' or metric == 'clip_img_similarity':
                values.append(avg_metrics[metric] * 100)
            else:
                values.append(avg_metrics[metric])
        else:
            values.append(0)

    plt.figure(figsize=(10, 6))
    bars = plt.bar(labels, values, color=['skyblue', 'lightgreen', 'coral'])

    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.2f}', ha='center', va='bottom')

    plt.ylabel('Values')
    plt.title(f'Average Image Quality Metrics - {model1}')
    plt.ylim(0, max(values) * 1.2)

    plt.tight_layout()
    plt.show()

"""## Main Part"""

def main():
    # Copy images from Drive
    image_files = copy_images_from_drive(drive_input_dir, local_input_dir)

    if not image_files:
        print("No images found!")
        return

    # Create degraded versions
    print("\n=== Creating degraded images ===")
    create_degraded_images(image_files, local_input_dir, local_degraded_dir, drive_degraded_dir, scale_factor=0.5)

    # Load CLIP model
    print("\n=== Loading CLIP model ===")
    clip_model, clip_preprocess, clip_device = load_clip_model()

    # Load StableSR
    print("\n=== Loading StableSR model ===")
    pipe, device = load_stablesr_model()

    if pipe is None:
        print("Failed to load model. Exiting.")
        return

    # Get prompts
    prompts = get_landscape_prompts()

    # Process images - CORRECT function call
    print("\n=== Processing with StableSR ===")
    stablesr_results = process_all_images_stablesr(
        image_files=image_files,
        pipe=pipe,
        device=device,
        clip_model=clip_model,
        clip_preprocess=clip_preprocess,
        local_input_dir=local_input_dir,
        local_degraded_dir=local_degraded_dir,
        local_output_dir=local_output_dir,
        drive_output_dir=drive_output_dir,
        prompts=prompts
    )

    # Analyze results
    print("\n=== Analyzing Results ===")
    compare_model_results(stablesr_results, "StableSR")

    print(f"\nResults saved to: {drive_output_dir}")

if __name__ == "__main__":
    main()

