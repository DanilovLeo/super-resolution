# -*- coding: utf-8 -*-
"""sdxl_upscaler_no_text

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dQXWJ303C0QgZ-Bz2kRXX6-C-nVUUX7w

# Implementation of SDXL x4 Upscaler for super-resolution on landscape images (without text)
"""

# Install required packages
!pip install opencv-python matplotlib numpy torch torchvision diffusers transformers accelerate xformers
!pip install git+https://github.com/openai/CLIP.git

"""## Import Libraries"""

import os
import cv2
import numpy as np
import torch
from diffusers import StableDiffusionUpscalePipeline, DDIMScheduler
import matplotlib.pyplot as plt
from google.colab import drive
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from scipy.ndimage import gaussian_filter
import clip
from PIL import Image
from huggingface_hub import login
import gc
import time

"""## Mount Google Drive and Setup"""

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Authenticate with Hugging Face
from google.colab import userdata

try:
    hf_token = userdata.get('HF_TOKEN')
    if hf_token:
        os.environ['HUGGINGFACE_TOKEN'] = hf_token
        login(token=hf_token)
        print("✓ Successfully authenticated with Hugging Face!")
    else:
        print("⚠️ HF_TOKEN not found in secrets")
except Exception as e:
    print(f"❌ Authentication error: {e}")

# Set up directories
drive_input_dir = '/content/drive/MyDrive/images_no_text'
drive_output_dir = '/content/drive/MyDrive/real_stablesr_output_no_text'
drive_degraded_dir = '/content/drive/MyDrive/gan_degraded_images'

local_input_dir = '/content/input_images'
local_output_dir = '/content/output_images'
local_degraded_dir = '/content/degraded_images'

# Create directories
for dir_path in [drive_output_dir, drive_degraded_dir, local_input_dir, local_output_dir, local_degraded_dir]:
    os.makedirs(dir_path, exist_ok=True)

"""## Memory management functions"""

def clear_gpu_memory():
    """Clear GPU memory"""
    gc.collect()
    torch.cuda.empty_cache()
    if hasattr(torch.cuda, 'ipc_collect'):
        torch.cuda.ipc_collect()

def get_max_image_size():
    """Get maximum image size based on available GPU memory"""
    if not torch.cuda.is_available():
        return 1024  # Default for CPU

    # Get available GPU memory in GB
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)

    # Conservative estimate
    if gpu_memory > 32:
        return 2048
    elif gpu_memory > 16:
        return 1536
    elif gpu_memory > 8:
        return 1024
    else:
        return 768

"""## Copy Images from Google Drive"""

def copy_images_from_drive(drive_input_dir, local_input_dir):
    """Copy images from Google Drive to local directory"""
    if not os.path.exists(drive_input_dir):
        print(f"Error: Directory {drive_input_dir} does not exist.")
        return []

    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
    image_files = [f for f in os.listdir(drive_input_dir)
                  if os.path.isfile(os.path.join(drive_input_dir, f)) and
                  f.lower().endswith(image_extensions)]

    if not image_files:
        print(f"No image files found in {drive_input_dir}")
        return []

    print(f"Found {len(image_files)} images. Copying...")
    for filename in image_files:
        src_path = os.path.join(drive_input_dir, filename)
        dst_path = os.path.join(local_input_dir, filename)
        os.system(f'cp "{src_path}" "{dst_path}"')
    return image_files

"""## Create Degraded images"""

def create_degraded_images(image_files, local_input_dir, local_degraded_dir, drive_degraded_dir, scale_factor=0.5):
    """Create degraded versions of images"""
    degraded_files = []
    for filename in image_files:
        input_path = os.path.join(local_input_dir, filename)
        degraded_filename = os.path.splitext(filename)[0] + '_degraded' + os.path.splitext(filename)[1]
        degraded_path = os.path.join(local_degraded_dir, degraded_filename)

        img = cv2.imread(input_path, cv2.IMREAD_COLOR)
        if img is None:
            continue

        h, w = img.shape[:2]
        lr_h, lr_w = int(h * scale_factor), int(w * scale_factor)

        # Downscale and degrade
        img_lr = cv2.resize(img, (lr_w, lr_h), interpolation=cv2.INTER_CUBIC)
        _, buffer = cv2.imencode('.jpg', img_lr, [cv2.IMWRITE_JPEG_QUALITY, 50])
        img_lr = cv2.imdecode(buffer, cv2.IMREAD_COLOR)
        img_lr = cv2.GaussianBlur(img_lr, (3, 3), 0.8)

        cv2.imwrite(degraded_path, img_lr)
        os.system(f'cp "{degraded_path}" "{os.path.join(drive_degraded_dir, degraded_filename)}"')
        degraded_files.append(degraded_filename)
    return degraded_files

"""## Initialize CLIP Model for Evaluation"""

def load_clip_model():
    """Load CLIP model"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

"""## Degradation Estimation function"""

def estimate_degradation(img):
    """Estimate degradation parameters of the input image"""
    # Convert to grayscale for analysis
    if len(img.shape) > 2:
        if img.shape[2] == 3:  # RGB
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        else:  # Assuming BGR
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()

    # Estimate blur (using variance of Laplacian)
    blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()

    # Estimate noise (using filter-based method)
    noise_score = estimate_noise(gray)

    # Estimate compression artifacts (using blockiness)
    compression_score = estimate_compression(gray)

    return {
        'blur': blur_score,
        'noise': noise_score,
        'compression': compression_score
    }

def estimate_noise(gray_img):
    """Estimate noise level in an image using high-frequency components"""
    blurred = cv2.GaussianBlur(gray_img, (5, 5), 0)
    noise = gray_img.astype(np.float32) - blurred.astype(np.float32)
    return np.std(noise)

def estimate_compression(gray_img):
    """Estimate JPEG compression level based on blockiness"""
    h, w = gray_img.shape
    block_size = 8  # JPEG uses 8x8 blocks

    # Check if image is too small
    if h < block_size * 2 or w < block_size * 2:
        return 0

    # Calculate blockiness score by measuring differences at block boundaries
    blockiness = 0
    for i in range(block_size, h, block_size):
        blockiness += np.sum(np.abs(gray_img[i,:].astype(float) - gray_img[i-1,:].astype(float)))

    for j in range(block_size, w, block_size):
        blockiness += np.sum(np.abs(gray_img[:,j].astype(float) - gray_img[:,j-1].astype(float)))

    # Normalize by number of pixels
    total_boundary_pixels = (h // block_size) * w + (w // block_size) * h
    if total_boundary_pixels > 0:
        blockiness /= total_boundary_pixels

    return blockiness

"""## Metrics Functions"""

def calculate_metrics(original_img, enhanced_img, clip_model=None, clip_preprocess=None, prompt=None, device=None):
    """Calculate image quality metrics"""
    if original_img.shape != enhanced_img.shape:
        enhanced_img = cv2.resize(enhanced_img, (original_img.shape[1], original_img.shape[0]),
                                 interpolation=cv2.INTER_CUBIC)

    def rgb_to_y(img):
        return 0.299 * img[:,:,0] + 0.587 * img[:,:,1] + 0.114 * img[:,:,2]

    original_y = rgb_to_y(original_img)
    enhanced_y = rgb_to_y(enhanced_img)

    psnr = peak_signal_noise_ratio(original_y, enhanced_y, data_range=255)
    ssim = structural_similarity(original_y, enhanced_y, data_range=255)

    def calculate_sharpness(img):
        gray = img if len(img.shape) == 2 else rgb_to_y(img)
        return cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F).var()

    original_sharpness = calculate_sharpness(original_img)
    enhanced_sharpness = calculate_sharpness(enhanced_img)
    sharpness_increase = (enhanced_sharpness - original_sharpness) / (original_sharpness + 1e-8) * 100

    def calculate_details(img):
        gray = img if len(img.shape) == 2 else rgb_to_y(img)
        blurred = gaussian_filter(gray, sigma=3)
        high_freq = np.abs(gray - blurred)
        return np.mean(high_freq)

    original_details = calculate_details(original_img)
    enhanced_details = calculate_details(enhanced_img)
    detail_increase = (enhanced_details - original_details) / (original_details + 1e-8) * 100

    metrics = {
        'psnr': psnr,
        'ssim': ssim,
        'sharpness_increase': sharpness_increase,
        'detail_increase': detail_increase
    }

    # Add CLIP metrics if available
    if clip_model is not None and clip_preprocess is not None and device is not None:
        try:
            original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
            enhanced_rgb = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)

            original_pil = Image.fromarray(original_rgb)
            enhanced_pil = Image.fromarray(enhanced_rgb)

            with torch.no_grad():
                original_features = clip_model.encode_image(clip_preprocess(original_pil).unsqueeze(0).to(device))
                enhanced_features = clip_model.encode_image(clip_preprocess(enhanced_pil).unsqueeze(0).to(device))

                original_features = original_features / original_features.norm(dim=-1, keepdim=True)
                enhanced_features = enhanced_features / enhanced_features.norm(dim=-1, keepdim=True)

                clip_img_similarity = torch.nn.functional.cosine_similarity(original_features, enhanced_features).item()
                metrics['clip_img_similarity'] = clip_img_similarity

                if prompt:
                    text = clip.tokenize([prompt]).to(device)
                    text_features = clip_model.encode_text(text)
                    text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                    prompt_img_similarity = torch.nn.functional.cosine_similarity(enhanced_features, text_features).item()
                    metrics['prompt_img_similarity'] = prompt_img_similarity
        except Exception as e:
            print(f"CLIP metric error: {e}")

    return metrics

"""## Define StableSR Model"""

def load_real_stablesr_model():
    """Load a real StableSR-like model using SD Upscaler"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    try:
        # Use the specialized upscaler model
        model_id = "stabilityai/stable-diffusion-x4-upscaler"

        # Load with optimized configuration
        pipe = StableDiffusionUpscalePipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            use_safetensors=True,
            variant="fp16" if device == "cuda" else None
        )

        # Use DDIM scheduler for better quality
        pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)

        # Enable memory optimizations
        if device == "cuda":
            pipe.enable_model_cpu_offload()
            pipe.enable_vae_slicing()
            if hasattr(pipe, 'enable_xformers_memory_efficient_attention'):
                pipe.enable_xformers_memory_efficient_attention()

        print("Successfully loaded Real StableSR model (SD Upscaler)")
        return pipe.to(device), device
    except Exception as e:
        print(f"Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return None, device

def get_landscape_prompts():
    """Get specific prompts for each landscape image"""
    return [
        "A towering waterfall cascading down a rugged cliff at sunset, golden light illuminating mist and vibrant greenery below, ultra-detailed, photorealistic, high-quality super-resolution, realistic water spray, dramatic sky, fine rock textures",
        "A tranquil marshland with still, reflective water surrounded by tall reeds and distant tree line under soft daylight, super-resolution, ultra-detailed, photorealistic, crisp reed structures, subtle water ripples",
        "A fast mountain stream rushing through rocky canyon with turquoise water and autumn foliage, super-resolution, photorealistic, highly detailed rock surfaces and whitewater foam",
        "A high-angle view of terraced green hillsides overlooking a deep mountain valley bathed in morning sunbeams through clouds, super-resolution, ultra-detailed, realistic light rays, fine terrain textures",
        "A small waterfall flowing over mossy rocks in early spring, bare trees above and bright blue sky, super-resolution, photorealistic, crisp water flow, detailed rock and bark textures",
        "Aerial view of a long turquoise lake flanked by dense green forests and distant mountains under partly cloudy sky, super-resolution, ultra-detailed, realistic water gradients, fine foliage textures",
        "A remote alpine lake in a barren mountainous plateau with misty clouds and muted colors, super-resolution, photorealistic, highly detailed terrain and water reflections",
        "A misty autumn mountainside with low-lying clouds drifting among colorful trees reflected in a calm lake, super-resolution, ultra-detailed, realistic leaf textures and soft cloud wisps",
        "A crystal-clear mountain lake perfectly mirroring snow-capped peaks and fluffy white clouds against a bright blue sky, super-resolution, photorealistic, ultra-detailed water reflection, fine rock and tree details",
        "A lush green rolling landscape with a winding river under a vivid blue sky dotted with small white clouds, super-resolution, photorealistic, ultra-detailed grass and tree textures, realistic water highlights"
    ]

"""## Process Images"""

def process_image_real_stablesr(degraded_path, output_path, pipe, device, prompt,
                           clip_model=None, clip_preprocess=None, original_path=None,
                           num_inference_steps=30):
    """Process a single image with Real StableSR approach"""
    # Read degraded image
    img = cv2.imread(degraded_path, cv2.IMREAD_COLOR)
    if img is None:
        print(f"Error reading {degraded_path}")
        return None, None, None

    # Convert to RGB for PIL
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Estimate degradation parameters
    degradation = estimate_degradation(img_rgb)
    print(f"Degradation estimates: Blur={degradation['blur']:.2f}, Noise={degradation['noise']:.2f}, Compression={degradation['compression']:.2f}")

    # Calculate adaptive noise level based on degradation
    # Higher noise for more degraded images
    noise_level = int(min(100, max(20,
                             30 + degradation['noise'] * 2.0 - degradation['blur'] * 0.05 + degradation['compression'] * 5.0)))
    print(f"Using adaptive noise level: {noise_level}")

    # Convert to PIL Image for the pipeline
    img_pil = Image.fromarray(img_rgb)

    # Start timer
    start_time = time.time()

    try:
        # Clear GPU memory before processing
        clear_gpu_memory()

        # Process with the upscaler pipeline
        with torch.no_grad():  # Reduce memory usage
            result = pipe(
                prompt=prompt,
                image=img_pil,
                noise_level=noise_level,
                num_inference_steps=num_inference_steps,
                guidance_scale=7.5,  # Default for upscaler
            ).images[0]

        # Convert back to OpenCV format
        enhanced_img = cv2.cvtColor(np.array(result), cv2.COLOR_RGB2BGR)

        # Calculate processing time
        process_time = time.time() - start_time
        print(f"Processing time: {process_time:.2f} seconds")

        # Save the enhanced output
        cv2.imwrite(output_path, enhanced_img)
        print(f"Saved enhanced image to {output_path}")

        # Calculate metrics
        metrics = calculate_metrics(
            img, enhanced_img,
            clip_model=clip_model,
            clip_preprocess=clip_preprocess,
            prompt=prompt,
            device=device
        )

        # Print metrics
        print("\nImage Quality Metrics:")
        print(f"PSNR: {metrics['psnr']:.2f} dB")
        print(f"SSIM: {metrics['ssim']:.4f}")
        print(f"Sharpness increase: {metrics['sharpness_increase']:.2f}%")
        print(f"Detail increase: {metrics['detail_increase']:.2f}%")
        if 'clip_img_similarity' in metrics:
            print(f"CLIP Image Similarity: {metrics['clip_img_similarity']:.4f}")
        if 'prompt_img_similarity' in metrics:
            print(f"Prompt-Image Similarity: {metrics['prompt_img_similarity']:.4f}")

        return img, enhanced_img, metrics

    except Exception as e:
        print(f"Error processing image: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None

def process_all_images_real_stablesr(image_files, pipe, device, clip_model, clip_preprocess,
                               local_input_dir, local_degraded_dir, local_output_dir, drive_output_dir,
                               prompts=None):
    """Process all images with Real StableSR approach"""
    all_metrics = []

    # Make sure we have enough prompts (repeat if necessary)
    if prompts and len(prompts) < len(image_files):
        prompts = (prompts * ((len(image_files) // len(prompts)) + 1))[:len(image_files)]

    for i, filename in enumerate(image_files):
        # Clear memory before each image
        clear_gpu_memory()

        base_filename = os.path.splitext(filename)[0]
        degraded_filename = base_filename + '_degraded' + os.path.splitext(filename)[1]

        input_path = os.path.join(local_input_dir, filename)
        degraded_path = os.path.join(local_degraded_dir, degraded_filename)
        output_filename = base_filename + '_RealStableSR.png'
        output_path = os.path.join(local_output_dir, output_filename)

        # Get prompt for this image
        prompt = prompts[i] if prompts and i < len(prompts) else "high quality detailed landscape image"

        print(f"\n{'='*80}\nProcessing {filename} with Real StableSR...")
        print(f"Prompt: {prompt}")

        try:
            degraded_img, output_img, metrics = process_image_real_stablesr(
                degraded_path, output_path, pipe, device, prompt,
                clip_model=clip_model, clip_preprocess=clip_preprocess, original_path=input_path
            )

            if degraded_img is None or output_img is None:
                print(f"Error processing {filename}")
                continue

            # Store metrics for later analysis
            metrics['filename'] = filename
            metrics['model'] = "RealStableSR"
            all_metrics.append(metrics)

            # Copy to Google Drive
            drive_output_path = os.path.join(drive_output_dir, output_filename)
            os.system(f'cp "{output_path}" "{drive_output_path}"')
            print(f"Saved to Google Drive: {drive_output_path}")

            # Read original image for display
            orig_img = cv2.imread(input_path, cv2.IMREAD_COLOR)
            orig_img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)
            degraded_img_rgb = cv2.cvtColor(degraded_img, cv2.COLOR_BGR2RGB)
            output_img_rgb = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)

            # Display comparison
            plt.figure(figsize=(20, 12))

            # Original image
            plt.subplot(1, 3, 1)
            plt.imshow(orig_img_rgb)
            plt.title(f"Original: {filename}\nDimensions: {orig_img.shape[1]}x{orig_img.shape[0]}", fontsize=12)
            plt.axis('off')

            # Degraded image
            plt.subplot(1, 3, 2)
            degraded_resized = cv2.resize(degraded_img_rgb, (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_NEAREST)
            plt.imshow(degraded_resized)
            plt.title(f"Degraded: {degraded_filename}\nDimensions: {degraded_img.shape[1]}x{degraded_img.shape[0]}\n(Resized for display)", fontsize=12)
            plt.axis('off')

            # Enhanced image
            plt.subplot(1, 3, 3)
            enhanced_resized = cv2.resize(output_img_rgb, (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_CUBIC) if output_img.shape != orig_img.shape else output_img_rgb
            plt.imshow(enhanced_resized)

            title_text = f"Enhanced (Real StableSR): {output_filename}\nDimensions: {output_img.shape[1]}x{output_img.shape[0]}\n"
            title_text += f"PSNR: {metrics['psnr']:.2f} dB, SSIM: {metrics['ssim']:.4f}\n"
            title_text += f"Sharpness Inc: {metrics['sharpness_increase']:.2f}%, Detail Inc: {metrics['detail_increase']:.2f}%"

            if 'clip_img_similarity' in metrics:
                title_text += f"\nCLIP Img Sim: {metrics['clip_img_similarity']:.4f}"
            if 'prompt_img_similarity' in metrics:
                title_text += f", Prompt Sim: {metrics['prompt_img_similarity']:.4f}"

            plt.title(title_text, fontsize=12)
            plt.axis('off')

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"Error processing {filename}: {e}")
            import traceback
            traceback.print_exc()

    print(f"Processing with Real StableSR complete!")
    return all_metrics

"""

## Analyzing Results Function"""

def analyze_results(all_results, model_name="Real StableSR"):
    """Analyze and visualize results"""
    if not all_results:
        print("No results to analyze")
        return

    metrics_to_average = ['psnr', 'ssim', 'sharpness_increase', 'detail_increase',
                        'clip_img_similarity', 'prompt_img_similarity']
    avg_metrics = {}

    for metric in metrics_to_average:
        valid_results = [r[metric] for r in all_results if metric in r]
        if valid_results:
            avg_metrics[metric] = sum(valid_results) / len(valid_results)

    print(f"\nAverage Metrics for {model_name}:")
    print(f"{'Metric':<20} {'Value':<15}")
    print("-" * 35)
    for metric, value in avg_metrics.items():
        print(f"{metric:<20} {value:<15.4f}")

    # Create visualization
    metrics_to_plot = ['psnr', 'ssim', 'clip_img_similarity']
    labels = ['PSNR (dB)', 'SSIM (x100)', 'CLIP Image Similarity (x100)']

    values = []
    for i, metric in enumerate(metrics_to_plot):
        if metric in avg_metrics:
            # Scale SSIM and CLIP similarity for better visualization
            if metric == 'ssim' or metric == 'clip_img_similarity':
                values.append(avg_metrics[metric] * 100)
            else:
                values.append(avg_metrics[metric])
        else:
            values.append(0)

    plt.figure(figsize=(12, 6))
    bars = plt.bar(labels, values, color=['skyblue', 'lightgreen', 'coral'])

    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.2f}', ha='center', va='bottom')

    plt.ylabel('Values')
    plt.title(f'Average Image Quality Metrics - {model_name}')
    plt.ylim(0, max(values) * 1.2)

    plt.tight_layout()
    plt.show()

    # Detailed analysis of each metric
    for metric in metrics_to_average:
        if all(metric in result for result in all_results):
            values = [result[metric] for result in all_results]
            filenames = [result['filename'] for result in all_results]

            plt.figure(figsize=(14, 6))
            bars = plt.bar(filenames, values, color='skyblue')

            plt.title(f'{metric.replace("_", " ").title()} by Image')
            plt.xticks(rotation=45, ha='right')
            plt.ylabel(metric.replace("_", " ").title())
            plt.tight_layout()
            plt.show()

"""## Main Part"""

def main():
    # Copy images from Drive
    image_files = copy_images_from_drive(drive_input_dir, local_input_dir)

    if not image_files:
        print("No images found!")
        return

    # Create degraded versions
    print("\n=== Creating degraded versions of images ===")
    create_degraded_images(image_files, local_input_dir, local_degraded_dir, drive_degraded_dir, scale_factor=0.5)

    # Load CLIP model for evaluation
    print("\n=== Loading CLIP model for evaluation ===")
    clip_model, clip_preprocess, clip_device = load_clip_model()

    # Load Real StableSR model
    print("\n=== Loading Real StableSR model ===")
    pipe, device = load_real_stablesr_model()

    if pipe is None:
        print("Failed to load model. Exiting.")
        return

    # Get prompts for landscape images
    prompts = get_landscape_prompts()

    # Process images with Real StableSR
    print("\n=== Processing with Real StableSR ===")
    results = process_all_images_real_stablesr(
        image_files=image_files,
        pipe=pipe,
        device=device,
        clip_model=clip_model,
        clip_preprocess=clip_preprocess,
        local_input_dir=local_input_dir,
        local_degraded_dir=local_degraded_dir,
        local_output_dir=local_output_dir,
        drive_output_dir=drive_output_dir,
        prompts=prompts
    )

    # Analyze results
    print("\n=== Analyzing Results ===")
    analyze_results(results, "Real StableSR")

    print(f"\nProcessing complete. Results saved to: {drive_output_dir}")

if __name__ == "__main__":
    main()

